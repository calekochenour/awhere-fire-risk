{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import base64\n",
    "from datetime import date\n",
    "import requests\n",
    "#from abc import ABC\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import geopandas as gpd\n",
    "\n",
    "from awhere_classes import AWhereAPI\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Define aWhere API key and secret\n",
    "api_key = os.environ.get('AWHERE_API_KEY')\n",
    "api_secret = os.environ.get('AWHERE_API_SECRET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2: Subclass - Agronomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agronomics(AWhereAPI):\n",
    "    def __init__(self, api_key, api_secret, base_64_encoded_secret_key=None, auth_token=None, api_url=None):\n",
    "        super(Agronomics, self).__init__(api_key, api_secret,\n",
    "                                      base_64_encoded_secret_key, auth_token)\n",
    "\n",
    "        self.api_url = 'https://api.awhere.com/v2/agronomics'\n",
    "\n",
    "    def get_data():\n",
    "        pass\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_data():\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_data(df, lon_lat_cols, drop_cols, name_map):\n",
    "        \"\"\"Converts dataframe to geodataframe,\n",
    "        drops unnecessary columns, and renames\n",
    "        columns.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : dataframe\n",
    "            Input dataframe.\n",
    "\n",
    "        lon_lat_cols : list\n",
    "            List containing the column name for longitude (list[0])\n",
    "            and latitude (list[1]) attributes.\n",
    "\n",
    "        drop_cols : list (of str)\n",
    "            List of column names to be dropped.\n",
    "\n",
    "        name_map : dict\n",
    "            Dictionaty mapping old columns names (keys)\n",
    "            to new column names (values).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gdf : geodataframe\n",
    "            Cleaned geodataframe.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        \"\"\"\n",
    "        # Define CRS (EPSG 4326) - make this a parameter?\n",
    "        crs = {'init': 'epsg:4326'}\n",
    "\n",
    "        # Rename index - possibly as option, or take care of index prior?\n",
    "        #df.index.rename('date_rename', inplace=True)\n",
    "\n",
    "        # Create copy of input dataframe; prevents altering the original\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Convert to geodataframe\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df_copy, crs=crs, geometry=gpd.points_from_xy(\n",
    "                df[lon_lat_cols[0]],\n",
    "                df[lon_lat_cols[1]])\n",
    "        )\n",
    "\n",
    "        # Add lat/lon columns to drop columns list\n",
    "        drop_cols += lon_lat_cols\n",
    "\n",
    "        # Drop columns\n",
    "        gdf.drop(columns=drop_cols, axis=1, inplace=True)\n",
    "\n",
    "        # Rename columns\n",
    "        gdf.rename(columns=name_map, inplace=True)\n",
    "\n",
    "        # Return cleaned up geodataframe\n",
    "        return gdf\n",
    "    \n",
    "#     @classmethod\n",
    "#     def api_to_gdf(): # (cls, api_object, kwargs=None)\n",
    "#         pass\n",
    "    \n",
    "    @classmethod ## POSSIBLY DEFINE THIS AT CURRENT LEVEL IF STRUCTURES MATCH\n",
    "    def api_to_gdf(cls, api_object, kwargs=None):\n",
    "        \"\"\"kwargs is a dictionary that provides values beyond the default;\n",
    "        unpack dictionary if it exists\n",
    "        \n",
    "        kwargs are the parameters to get_data() method\n",
    "\n",
    "        kwargs={'start_day': '03-04', 'end_day': '03-07', 'offset': 2}\n",
    "        \"\"\"\n",
    "        api_data_json = api_object.get_data(\n",
    "            **kwargs) if kwargs else api_object.get_data()\n",
    "\n",
    "        api_data_df =  cls.extract_data(api_data_json)\n",
    "\n",
    "        api_data_gdf = cls.clean_data(\n",
    "            api_data_df,\n",
    "            cls.coord_cols,\n",
    "            cls.drop_cols,\n",
    "            cls.rename_map\n",
    "        )\n",
    "\n",
    "        return api_data_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro = Agronomics(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro.api_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3: Sub-sub-class - AgronomicsLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsLocation(Agronomics):\n",
    "    \n",
    "    def __init__(self, api_key, api_secret, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsLocation, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token)\n",
    "\n",
    "        self.api_url = f\"{self.api_url}/locations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_locations = AgronomicsLocation(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_locations.api_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3: Sub-sub-class - AgronomicsField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsField(Agronomics):\n",
    "    \n",
    "    def __init__(self, api_key, api_secret, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsField, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token)\n",
    "\n",
    "        self.api_url = f\"{self.api_url}/fields\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4: Sub-sub-sub-class - AgronomicsLocationValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsLocationValues(AgronomicsLocation):\n",
    "\n",
    "    # Class variables for clean_data() function\n",
    "    # Single day\n",
    "    day_coord_cols = ['location.latitude', 'location.longitude']\n",
    "\n",
    "    day_drop_cols = ['pet.units', '_links.self.href']\n",
    "\n",
    "    day_rename_map = {\n",
    "        \"gdd\": \"gdd_daily_total_cels\",\n",
    "        \"ppet\": \"ppet_daily_total\",\n",
    "        \"pet.amount\": \"pet_daily_total_mm\"\n",
    "    }  \n",
    "    \n",
    "    # Multi-day, total accumulation\n",
    "    total_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    total_drop_cols = ['precipitation.units', 'pet.units']\n",
    "    \n",
    "    total_rename_map = { ## PPET overall?? Range total\n",
    "        \"gdd\": \"gdd_range_total_cels\",\n",
    "        \"ppet\": \"ppet_range_total\", # This is accumulation of all daily PPET\n",
    "        \"precipitation.amount\": \"precip_range_total_mm\",\n",
    "        \"pet.amount\": \"pet_range_total_mm\"\n",
    "    }\n",
    "\n",
    "    # Multi-day, daily accumulation\n",
    "    daily_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    daily_drop_cols = ['pet.units', 'accumulatedPrecipitation.units',\n",
    "                       'accumulatedPet.units', '_links.self.href']\n",
    "\n",
    "    daily_rename_map = {\n",
    "        \"gdd\": \"gdd_daily_total_cels\",\n",
    "        \"ppet\": \"ppet_daily_total\",\n",
    "        \"accumulatedGdd\": \"gdd_rolling_total_cels\",\n",
    "        \"accumulatedPpet\": \"ppet_rolling_total\",\n",
    "        \"pet.amount\": \"pet_daily_total_mm\",\n",
    "        \"accumulatedPrecipitation.amount\": \"precip_rolling_total_mm\",\n",
    "        \"accumulatedPet.amount\": \"pet_rolling_total_mm\"\n",
    "    }\n",
    "\n",
    "    # Define lat/lon when intitializing class; no need to repeat for lat/lon\n",
    "    #  in get_data() because it is already programmed into api_url\n",
    "    def __init__(self, api_key, api_secret, latitude, longitude, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsLocationValues, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.api_url = f\"{self.api_url}/{self.latitude},{self.longitude}/agronomicvalues\"\n",
    "\n",
    "    def get_data(self, start_day=date.today().strftime(\"%m-%d\"), end_day=None, offset=0):\n",
    "        \"\"\"Returns aWhere Forecast Agronomic Values.\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Perform the HTTP request to obtain the norms for the Field\n",
    "        # Define URL variants\n",
    "        url_single_day = f\"{self.api_url}/{start_day}\"\n",
    "        url_multiple_days = f\"{self.api_url}/{start_day},{end_day}?limit=10&offset={offset}\"\n",
    "\n",
    "        # Get single day norms or date range\n",
    "        response = requests.get(url_multiple_days, headers=auth_headers) if end_day else requests.get(\n",
    "            url_single_day, headers=auth_headers)\n",
    "\n",
    "        # Return the norms\n",
    "        return response.json()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_data(agronomic_values):\n",
    "        \"\"\"Extracts data from the aWhere agronomic forecast\n",
    "        data in JSON format.\n",
    "        \"\"\"\n",
    "        # Extract lat/lon\n",
    "        latitude = agronomic_values.get('location').get('latitude')\n",
    "        longitude = agronomic_values.get('location').get('longitude')\n",
    "\n",
    "        # Check if more than one day\n",
    "        if agronomic_values.get('dailyValues'):\n",
    "\n",
    "            # Do these with a separate call, just like in Soil accumulation='daily'\n",
    "            #  accumulation='total'\n",
    "\n",
    "            # DAILY ACCUMULATIONS\n",
    "            # Get daily forecasted accumulations\n",
    "            daily_accumulation = json_normalize(\n",
    "                agronomic_values.get('dailyValues'))\n",
    "\n",
    "            # Add lat/lon and set date as index\n",
    "            daily_accumulation['latitude'] = latitude\n",
    "            daily_accumulation['longitude'] = longitude\n",
    "            daily_accumulation.set_index(['date'], inplace=True)\n",
    "\n",
    "            # TOTAL ACCUMULATION\n",
    "            # Get total forecasted accumulations through all days\n",
    "            total_accumulation = json_normalize(\n",
    "                agronomic_values.get('accumulations'))\n",
    "\n",
    "            # Get list of dates, add start/end dates, set date range as index\n",
    "            dates = [entry.get('date')\n",
    "                     for entry in agronomic_values.get('dailyValues')]\n",
    "            total_accumulation['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "            total_accumulation['start_day'] = dates[0]\n",
    "            total_accumulation['end_day'] = dates[-1]\n",
    "            total_accumulation.set_index(['date_range'], inplace=True)\n",
    "\n",
    "            # Add lat/lon\n",
    "            total_accumulation['latitude'] = latitude\n",
    "            total_accumulation['longitude'] = longitude\n",
    "\n",
    "            # Put dataframes in tuple (total accumulation, daily accumulation)\n",
    "            agronomics_df = (total_accumulation, daily_accumulation)\n",
    "\n",
    "        # Single day\n",
    "        else:\n",
    "            agronomics_df = json_normalize(agronomic_values)\n",
    "            # agronomics_df['latitude'] = latitude\n",
    "            # agronomics_df['longitude'] = longitude\n",
    "            agronomics_df.set_index(['date'], inplace=True)\n",
    "\n",
    "        return agronomics_df\n",
    "\n",
    "    @classmethod\n",
    "    def api_to_gdf(cls, api_object, value_type='single_day', kwargs=None):\n",
    "        \"\"\"\n",
    "        value_type can be 'single_day' or 'multi_day'.\n",
    "\n",
    "        kwargs is a dictionary that provides values beyond the default;\n",
    "        unpack dictionary if it exists\n",
    "\n",
    "        kwargs are the parameters to get_data() method\n",
    "\n",
    "        kwargs={'start_day': '03-04', 'end_day': '03-07', 'offset': 2}\n",
    "        \"\"\"\n",
    "        api_data_json = api_object.get_data(\n",
    "            **kwargs) if kwargs else api_object.get_data()\n",
    "\n",
    "        if value_type.lower() == 'single_day':\n",
    "            api_data_df = cls.extract_data(api_data_json)\n",
    "\n",
    "            api_data_gdf = cls.clean_data(\n",
    "                api_data_df,\n",
    "                cls.day_coord_cols,\n",
    "                cls.day_drop_cols,\n",
    "                cls.day_rename_map\n",
    "            )\n",
    "\n",
    "        elif value_type.lower() == 'multi_day':\n",
    "            api_data_df_total, api_data_df_daily = cls.extract_data(\n",
    "                api_data_json)\n",
    "\n",
    "            api_data_gdf_total = cls.clean_data(\n",
    "                api_data_df_total,\n",
    "                cls.total_coord_cols,\n",
    "                cls.total_drop_cols,\n",
    "                cls.total_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf_daily = cls.clean_data(\n",
    "                api_data_df_daily,\n",
    "                cls.daily_coord_cols,\n",
    "                cls.daily_drop_cols,\n",
    "                cls.daily_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf = (api_data_gdf_total, api_data_gdf_daily)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value type. Please choose 'single_day' or 'multi_day'.\")\n",
    "\n",
    "        return api_data_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4: Sub-sub-sub-class - AgronomicsLocationNorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsLocationNorms(AgronomicsLocation):\n",
    "\n",
    "    # Class variables for clean_data() function\n",
    "    \n",
    "    # https://developer.awhere.com/api/reference/agronomics/norms/geolocation\n",
    "    \n",
    "    \"\"\"The average ratio of Precipitation to Potential Evapotranspiration \n",
    "    over the years specified. When this value is above 1, then more rain fell \n",
    "    than the amount of likely water loss; if it's below 1, then more water was\n",
    "    likely lost than fell as rain. P/PET is most useful when calculated for a \n",
    "    range of days, as it is for this property, than for individual days.\"\"\"\n",
    "    \n",
    "    # Single day   \n",
    "    day_coord_cols = ['location.latitude', 'location.longitude']\n",
    "\n",
    "    day_drop_cols = ['pet.units', '_links.self.href']\n",
    "     \n",
    "    day_rename_map = {\n",
    "        \"gdd.average\": \"gdd_daily_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_daily_average_total_std_dev_cels\",\n",
    "        \"pet.average\": \"pet_daily_average_total_mm\",\n",
    "        \"pet.stdDev\": \"pet_daily_average_total_std_dev_mm\",\n",
    "        \"ppet.average\": \"ppet_daily_average_total\",\n",
    "        \"ppet.stdDev\": \"ppet_daily_average_total_std_dev\"\n",
    "    }\n",
    "     \n",
    "    # Multi-day, total accumulation\n",
    "    total_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    total_drop_cols = ['precipitation.units', 'pet.units']\n",
    "\n",
    "    total_rename_map = {\n",
    "        \"gdd.average\": \"norms_gdd_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"norms_gdd_average_total_std_dev_cels\",\n",
    "        \"precipitation.average\": \"norms_precip_average_total_mm\",\n",
    "        \"precipitation.stdDev\": \"norms_precip_average_total_std_dev_mm\",\n",
    "        \"pet.average\": \"norms_pet_average_total_mm\",\n",
    "        \"pet.stdDev\": \"norms_pet_average_total_std_dev\",\n",
    "        \"ppet.average\": \"norms_ppet_average_total\",\n",
    "        \"ppet.stdDev\": \"norms_ppet_average_total_std_dev\"\n",
    "    }\n",
    "\n",
    "    total_rename_map = {\n",
    "        \"gdd.average\": \"gdd_range_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_range_average_total_std_dev_cels\",\n",
    "        \"precipitation.average\": \"precip_range_average_total_mm\",\n",
    "        \"precipitation.stdDev\": \"precip_range_average_total_std_dev_mm\",\n",
    "        \"pet.average\": \"pet_range_average_total_mm\",\n",
    "        \"pet.stdDev\": \"pet_range_average_total_std_dev\",\n",
    "        # Why doesn't this match with precip_avg/pet_avg? \n",
    "        # What causes this difference?\n",
    "        # Is it the average of each of individual PPET daily values?\n",
    "        # Seems like it\n",
    "        \"ppet.average\": \"ppet_range_daily_average\", \n",
    "        \"ppet.stdDev\": \"ppet_range_daily_average_std_dev\"\n",
    "    }\n",
    "    \n",
    "    # Multi-day, daily accumulation\n",
    "    daily_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    daily_drop_cols = ['pet.units', 'accumulatedPrecipitation.units',\n",
    "                       'accumulatedPet.units', '_links.self.href']\n",
    "    \n",
    "    daily_rename_map = {       \n",
    "        \"gdd.average\": \"gdd_daily_average_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_daily_average_std_dev_cels\",\n",
    "        \"pet.average\": \"pet_daily_average_mm\",\n",
    "        \"pet.stdDev\": \"pet_daily_average_std_dev_mm\",\n",
    "        \"ppet.average\": \"ppet_daliy_average\",\n",
    "        \"ppet.stdDev\": \"ppet_daily_average_std_dev\",\n",
    "        \"accumulatedGdd.average\": \"gdd_rolling_total_average\",\n",
    "        \"accumulatedGdd.stdDev\": \"gdd_rolling_total_average_std_dev\",\n",
    "        \"accumulatedPrecipitation.average\": \"precip_rolling_total_average_mm\",\n",
    "        \"accumulatedPrecipitation.stdDev\": \"precip_rolling_total_average_std_dev_mm\",\n",
    "        \"accumulatedPet.average\": \"pet_rolling_total_average_mm\",\n",
    "        \"accumulatedPet.stdDev\": \"pet_rolling_total_average_std_dev_mm\", \n",
    "        \"accumulatedPpet.average\": \"ppet_rolling_total_average\",\n",
    "        \"accumulatedPpet.stdDev\": \"ppet_rolling_total_average_std_dev\"\n",
    "    }\n",
    "\n",
    "    # Define lat/lon when intitializing class; no need to repeat for lat/lon\n",
    "    #  in get_data() because it is already programmed into api_url\n",
    "    def __init__(self, api_key, api_secret, latitude, longitude, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsLocationNorms, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.api_url = f\"{self.api_url}/{self.latitude},{self.longitude}/agronomicnorms\"\n",
    "\n",
    "    def get_data(self, start_day='01-01', end_day=None, offset=0):\n",
    "        \"\"\"Returns aWhere Historic Agronomic Norms.\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Perform the HTTP request to obtain the norms for the Field\n",
    "        # Define URL variants\n",
    "        url_single_day = f\"{self.api_url}/{start_day}\"\n",
    "        url_multiple_days = f\"{self.api_url}/{start_day},{end_day}?limit=10&offset={offset}\"\n",
    "\n",
    "        # Get single day norms or date range\n",
    "        response = requests.get(url_multiple_days, headers=auth_headers) if end_day else requests.get(\n",
    "            url_single_day, headers=auth_headers)\n",
    "\n",
    "        # Return the norms\n",
    "        return response.json()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_data(agronomic_norms):\n",
    "        \"\"\"Extracts data from the aWhere agronomic norms\n",
    "        data in JSON format.\n",
    "        \"\"\"\n",
    "        # Extract lat/lon\n",
    "        latitude = agronomic_norms.get('location').get('latitude')\n",
    "        longitude = agronomic_norms.get('location').get('longitude')\n",
    "\n",
    "        # Check if more than one day\n",
    "        if agronomic_norms.get('dailyNorms'):\n",
    "\n",
    "            # DAILY ACCUMULATION NORMS\n",
    "            # Get daily accumulation norms\n",
    "            daily_norms = json_normalize(\n",
    "                agronomic_norms.get('dailyNorms'))\n",
    "\n",
    "            # Add lat/lon and set date as index\n",
    "            daily_norms['latitude'] = latitude\n",
    "            daily_norms['longitude'] = longitude\n",
    "            daily_norms.set_index(['day'], inplace=True)\n",
    "\n",
    "            # TOTAL ACCUMULATION NORMS\n",
    "            # Get average accumulations through all days\n",
    "            total_norms = json_normalize(\n",
    "                agronomic_norms.get('averageAccumulations'))\n",
    "\n",
    "            # Get list of dates, add start/end dates, set date range as index\n",
    "            dates = [entry.get('day')\n",
    "                     for entry in agronomic_norms.get('dailyNorms')]\n",
    "            total_norms['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "            total_norms['start_day'] = dates[0]\n",
    "            total_norms['end_day'] = dates[-1]\n",
    "            total_norms.set_index(['date_range'], inplace=True)\n",
    "\n",
    "            # Add lat/lon\n",
    "            total_norms['latitude'] = latitude\n",
    "            total_norms['longitude'] = longitude\n",
    "\n",
    "            # Put dataframes in tuple (total norms, daily norms)\n",
    "            agronomics_df = (total_norms, daily_norms)\n",
    "\n",
    "        # Single day\n",
    "        else:\n",
    "            agronomics_df = json_normalize(agronomic_norms)\n",
    "            # agronomics_df['latitude'] = latitude\n",
    "            # agronomics_df['longitude'] = longitude\n",
    "            agronomics_df.set_index(['day'], inplace=True)\n",
    "\n",
    "        return agronomics_df\n",
    "\n",
    "    @classmethod\n",
    "    def api_to_gdf(cls, api_object, value_type='single_day', kwargs=None):\n",
    "        \"\"\"\n",
    "        value_type can be 'single_day' or 'multi_day'.\n",
    "\n",
    "        kwargs is a dictionary that provides values beyond the default;\n",
    "        unpack dictionary if it exists\n",
    "\n",
    "        kwargs are the parameters to get_data() method\n",
    "\n",
    "        kwargs={'start_day': '03-04', 'end_day': '03-07', 'offset': 2}\n",
    "        \"\"\"\n",
    "        api_data_json = api_object.get_data(\n",
    "            **kwargs) if kwargs else api_object.get_data()\n",
    "\n",
    "        if value_type.lower() == 'single_day':\n",
    "            api_data_df = cls.extract_data(api_data_json)\n",
    "\n",
    "            api_data_gdf = cls.clean_data(\n",
    "                api_data_df,\n",
    "                cls.day_coord_cols,\n",
    "                cls.day_drop_cols,\n",
    "                cls.day_rename_map\n",
    "            )\n",
    "\n",
    "        elif value_type.lower() == 'multi_day':\n",
    "            api_data_df_total, api_data_df_daily = cls.extract_data(\n",
    "                api_data_json)\n",
    "\n",
    "            api_data_gdf_total = cls.clean_data(\n",
    "                api_data_df_total,\n",
    "                cls.total_coord_cols,\n",
    "                cls.total_drop_cols,\n",
    "                cls.total_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf_daily = cls.clean_data(\n",
    "                api_data_df_daily,\n",
    "                cls.daily_coord_cols,\n",
    "                cls.daily_drop_cols,\n",
    "                cls.daily_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf = (api_data_gdf_total, api_data_gdf_daily)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value type. Please choose 'single_day' or 'multi_day'.\")\n",
    "\n",
    "        return api_data_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4: Sub-sub-sub-class - AgronomicsFieldValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsFieldValues(AgronomicsField):\n",
    "\n",
    "    # Class variables for clean_data() function\n",
    "    # Single day\n",
    "    day_coord_cols = ['location.latitude', 'location.longitude']\n",
    "\n",
    "    day_drop_cols = ['location.fieldId', 'pet.units', '_links.self.href',\n",
    "                     '_links.curies', '_links.awhere:field.href']\n",
    "\n",
    "    day_rename_map = {\n",
    "        \"gdd\": \"gdd_daily_total_cels\",\n",
    "        \"ppet\": \"ppet_daily_total\",\n",
    "        \"pet.amount\": \"pet_daily_total_mm\"\n",
    "    }\n",
    "\n",
    "    # Multi-day, total accumulation\n",
    "    total_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    total_drop_cols = ['precipitation.units', 'pet.units']\n",
    "\n",
    "    total_rename_map = { ## PPET overall?? Range total\n",
    "        \"gdd\": \"gdd_range_total_cels\",\n",
    "        \"ppet\": \"ppet_range_total\", # This is accumulation of all daily PPET\n",
    "        \"precipitation.amount\": \"precip_range_total_mm\",\n",
    "        \"pet.amount\": \"pet_range_total_mm\"\n",
    "    }\n",
    "\n",
    "    # Multi-day, daily accumulation\n",
    "    daily_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    daily_drop_cols = ['pet.units', 'accumulatedPrecipitation.units',\n",
    "                       'accumulatedPet.units', '_links.self.href',\n",
    "                       '_links.curies', '_links.awhere:field.href']\n",
    "\n",
    "    daily_rename_map = {\n",
    "        \"gdd\": \"gdd_daily_total_cels\",\n",
    "        \"ppet\": \"ppet_daily_total\",\n",
    "        \"accumulatedGdd\": \"gdd_rolling_total_cels\",\n",
    "        \"accumulatedPpet\": \"ppet_rolling_total\",\n",
    "        \"pet.amount\": \"pet_daily_total_mm\",\n",
    "        \"accumulatedPrecipitation.amount\": \"precip_rolling_total_mm\",\n",
    "        \"accumulatedPet.amount\": \"pet_rolling_total_mm\"\n",
    "    }\n",
    "\n",
    "    # Define lat/lon when intitializing class; no need to repeat for lat/lon\n",
    "    #  in get_data() because it is already programmed into api_url\n",
    "    def __init__(self, api_key, api_secret, field_id, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsFieldValues, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.field_id = field_id\n",
    "        self.api_url = f\"{self.api_url}/{self.field_id}/agronomicvalues\"\n",
    "\n",
    "    def get_data(self, start_day=date.today().strftime(\"%m-%d\"), end_day=None, offset=0):\n",
    "        \"\"\"Returns aWhere Forecast Agronomic Values for a provided field.\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Perform the HTTP request to obtain the norms for the Field\n",
    "        # Define URL variants\n",
    "        url_single_day = f\"{self.api_url}/{start_day}\"\n",
    "        url_multiple_days = f\"{self.api_url}/{start_day},{end_day}?limit=10&offset={offset}\"\n",
    "\n",
    "        # Get single day norms or date range\n",
    "        response = requests.get(url_multiple_days, headers=auth_headers) if end_day else requests.get(\n",
    "            url_single_day, headers=auth_headers)\n",
    "\n",
    "        # Return the norms\n",
    "        return response.json()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_data(agronomic_values):\n",
    "        \"\"\"Extracts data from the aWhere agronomic forecast\n",
    "        data in JSON format.\n",
    "        \"\"\"\n",
    "        # Extract lat/lon\n",
    "        latitude = agronomic_values.get('location').get('latitude')\n",
    "        longitude = agronomic_values.get('location').get('longitude')\n",
    "\n",
    "        # Check if more than one day\n",
    "        if agronomic_values.get('dailyValues'):\n",
    "\n",
    "            # Do these with a separate call, just like in Soil accumulation='daily'\n",
    "            #  accumulation='total'\n",
    "\n",
    "            # DAILY ACCUMULATIONS\n",
    "            # Get daily forecasted accumulations\n",
    "            daily_accumulation = json_normalize(\n",
    "                agronomic_values.get('dailyValues'))\n",
    "\n",
    "            # Add lat/lon and set date as index\n",
    "            daily_accumulation['latitude'] = latitude\n",
    "            daily_accumulation['longitude'] = longitude\n",
    "            daily_accumulation.set_index(['date'], inplace=True)\n",
    "\n",
    "            # TOTAL ACCUMULATION\n",
    "            # Get total forecasted accumulations through all days\n",
    "            total_accumulation = json_normalize(\n",
    "                agronomic_values.get('accumulations'))\n",
    "\n",
    "            # Get list of dates, add start/end dates, set date range as index\n",
    "            dates = [entry.get('date')\n",
    "                     for entry in agronomic_values.get('dailyValues')]\n",
    "            total_accumulation['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "            total_accumulation['start_day'] = dates[0]\n",
    "            total_accumulation['end_day'] = dates[-1]\n",
    "            total_accumulation.set_index(['date_range'], inplace=True)\n",
    "\n",
    "            # Add lat/lon\n",
    "            total_accumulation['latitude'] = latitude\n",
    "            total_accumulation['longitude'] = longitude\n",
    "\n",
    "            # Put dataframes in tuple (total accumulation, daily accumulation)\n",
    "            agronomics_df = (total_accumulation, daily_accumulation)\n",
    "\n",
    "        # Single day\n",
    "        else:\n",
    "            agronomics_df = json_normalize(agronomic_values)\n",
    "            # agronomics_df['latitude'] = latitude\n",
    "            # agronomics_df['longitude'] = longitude\n",
    "            agronomics_df.set_index(['date'], inplace=True)\n",
    "\n",
    "        return agronomics_df\n",
    "\n",
    "    @classmethod\n",
    "    def api_to_gdf(cls, api_object, value_type='single_day', kwargs=None):\n",
    "        \"\"\"\n",
    "        value_type can be 'single_day' or 'multi_day'.\n",
    "\n",
    "        kwargs is a dictionary that provides values beyond the default;\n",
    "        unpack dictionary if it exists\n",
    "\n",
    "        kwargs are the parameters to get_data() method\n",
    "\n",
    "        kwargs={'start_day': '03-04', 'end_day': '03-07', 'offset': 2}\n",
    "        \"\"\"\n",
    "        api_data_json = api_object.get_data(\n",
    "            **kwargs) if kwargs else api_object.get_data()\n",
    "\n",
    "        if value_type.lower() == 'single_day':\n",
    "            api_data_df = cls.extract_data(api_data_json)\n",
    "\n",
    "            api_data_gdf = cls.clean_data(\n",
    "                api_data_df,\n",
    "                cls.day_coord_cols,\n",
    "                cls.day_drop_cols,\n",
    "                cls.day_rename_map\n",
    "            )\n",
    "\n",
    "        elif value_type.lower() == 'multi_day':\n",
    "            api_data_df_total, api_data_df_daily = cls.extract_data(\n",
    "                api_data_json)\n",
    "\n",
    "            api_data_gdf_total = cls.clean_data(\n",
    "                api_data_df_total,\n",
    "                cls.total_coord_cols,\n",
    "                cls.total_drop_cols,\n",
    "                cls.total_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf_daily = cls.clean_data(\n",
    "                api_data_df_daily,\n",
    "                cls.daily_coord_cols,\n",
    "                cls.daily_drop_cols,\n",
    "                cls.daily_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf = (api_data_gdf_total, api_data_gdf_daily)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value type. Please choose 'single_day' or 'multi_day'.\")\n",
    "\n",
    "        return api_data_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_field = AgronomicsFieldValues(\n",
    "    api_key, api_secret, field_id='CO-RMNP-Bear-Lake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_field = AgronomicsFieldValues(\n",
    "    api_key, api_secret, field_id='CO-RMNP-Bear-Lake')\n",
    "\n",
    "AgronomicsFieldValues.api_to_gdf(agro_field, \n",
    "    value_type='single_day', \n",
    "    kwargs=None)\n",
    "\n",
    "total, daily = AgronomicsFieldValues.api_to_gdf(agro_field, \n",
    "    value_type='multi_day', \n",
    "    kwargs={'start_day': '03-03', 'end_day': '03-09'})\n",
    "\n",
    "total\n",
    "\n",
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, daily = AgronomicsFieldValues.api_to_gdf(agro_field, \n",
    "    value_type='multi_day', \n",
    "    kwargs={'start_day': '03-03', 'end_day': '03-09'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_field.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgronomicsFieldValues.extract_data(agro_field.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4: Sub-sub-sub-class - AgronomicsFieldNorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsFieldNorms(AgronomicsField):\n",
    "\n",
    "    # Class variables for clean_data() function\n",
    "    \n",
    "    # https://developer.awhere.com/api/reference/agronomics/norms/geolocation\n",
    "    \n",
    "    \"\"\"The average ratio of Precipitation to Potential Evapotranspiration \n",
    "    over the years specified. When this value is above 1, then more rain fell \n",
    "    than the amount of likely water loss; if it's below 1, then more water was\n",
    "    likely lost than fell as rain. P/PET is most useful when calculated for a \n",
    "    range of days, as it is for this property, than for individual days.\"\"\"\n",
    "    \n",
    "    # Single day   \n",
    "    day_coord_cols = ['location.latitude', 'location.longitude']\n",
    "\n",
    "    day_drop_cols = ['location.fieldId', 'pet.units', '_links.self.href',\n",
    "                     '_links.curies', '_links.awhere:field.href']\n",
    "\n",
    "    day_rename_map = {\n",
    "        \"gdd.average\": \"gdd_daily_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_daily_average_total_std_dev_cels\",\n",
    "        \"pet.average\": \"pet_daily_average_total_mm\",\n",
    "        \"pet.stdDev\": \"pet_daily_average_total_std_dev_mm\",\n",
    "        \"ppet.average\": \"ppet_daily_average_total\",\n",
    "        \"ppet.stdDev\": \"ppet_daily_average_total_std_dev\"\n",
    "    }\n",
    "     \n",
    "    # Multi-day, total accumulation\n",
    "    total_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    total_drop_cols = ['precipitation.units', 'pet.units']\n",
    "\n",
    "    total_rename_map = {\n",
    "        \"gdd.average\": \"gdd_range_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_range_average_total_std_dev_cels\",\n",
    "        \"precipitation.average\": \"precip_range_average_total_mm\",\n",
    "        \"precipitation.stdDev\": \"precip_range_average_total_std_dev_mm\",\n",
    "        \"pet.average\": \"pet_range_average_total_mm\",\n",
    "        \"pet.stdDev\": \"pet_range_average_total_std_dev\",\n",
    "        # Why doesn't this match with precip_avg/pet_avg? \n",
    "        # What causes this difference?\n",
    "        # Is it the average of each of individual PPET daily values?\n",
    "        # Seems like it\n",
    "        \"ppet.average\": \"ppet_range_daily_average\", \n",
    "        \"ppet.stdDev\": \"ppet_range_daily_average_std_dev\"\n",
    "    }\n",
    "\n",
    "    # Multi-day, daily accumulation\n",
    "    daily_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    daily_drop_cols = ['pet.units', 'accumulatedPrecipitation.units',\n",
    "                       'accumulatedPet.units', '_links.self.href',\n",
    "                       '_links.curies', '_links.awhere:field.href']\n",
    "\n",
    "    daily_rename_map = {       \n",
    "        \"gdd.average\": \"gdd_daily_average_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_daily_average_std_dev_cels\",\n",
    "        \"pet.average\": \"pet_daily_average_mm\",\n",
    "        \"pet.stdDev\": \"pet_daily_average_std_dev_mm\",\n",
    "        \"ppet.average\": \"ppet_daliy_average\",\n",
    "        \"ppet.stdDev\": \"ppet_daily_average_std_dev\",\n",
    "        \"accumulatedGdd.average\": \"gdd_rolling_total_average\",\n",
    "        \"accumulatedGdd.stdDev\": \"gdd_rolling_total_average_std_dev\",\n",
    "        \"accumulatedPrecipitation.average\": \"precip_rolling_total_average_mm\",\n",
    "        \"accumulatedPrecipitation.stdDev\": \"precip_rolling_total_average_std_dev_mm\",\n",
    "        \"accumulatedPet.average\": \"pet_rolling_total_average_mm\",\n",
    "        \"accumulatedPet.stdDev\": \"pet_rolling_total_average_std_dev_mm\", \n",
    "        \"accumulatedPpet.average\": \"ppet_rolling_total_average\",\n",
    "        \"accumulatedPpet.stdDev\": \"ppet_rolling_total_average_std_dev\"\n",
    "    }\n",
    "\n",
    "    # Define lat/lon when intitializing class; no need to repeat for lat/lon\n",
    "    #  in get_data() because it is already programmed into api_url\n",
    "    def __init__(self, api_key, api_secret, field_id, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsFieldNorms, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.field_id = field_id\n",
    "        self.api_url = f\"{self.api_url}/{self.field_id}/agronomicnorms\"\n",
    "\n",
    "    def get_data(self, start_day='01-01', end_day=None, offset=0):\n",
    "        \"\"\"Returns aWhere Historic Agronomic Norms.\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Perform the HTTP request to obtain the norms for the Field\n",
    "        # Define URL variants\n",
    "        url_single_day = f\"{self.api_url}/{start_day}\"\n",
    "        url_multiple_days = f\"{self.api_url}/{start_day},{end_day}?limit=10&offset={offset}\"\n",
    "\n",
    "        # Get single day norms or date range\n",
    "        response = requests.get(url_multiple_days, headers=auth_headers) if end_day else requests.get(\n",
    "            url_single_day, headers=auth_headers)\n",
    "\n",
    "        # Return the norms\n",
    "        return response.json()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_data(agronomic_norms):\n",
    "        \"\"\"Extracts data from the aWhere agronomic norms\n",
    "        data in JSON format.\n",
    "        \"\"\"\n",
    "        # Extract lat/lon\n",
    "        latitude = agronomic_norms.get('location').get('latitude')\n",
    "        longitude = agronomic_norms.get('location').get('longitude')\n",
    "\n",
    "        # Check if more than one day\n",
    "        if agronomic_norms.get('dailyNorms'):\n",
    "\n",
    "            # DAILY ACCUMULATION NORMS\n",
    "            # Get daily accumulation norms\n",
    "            daily_norms = json_normalize(\n",
    "                agronomic_norms.get('dailyNorms'))\n",
    "\n",
    "            # Add lat/lon and set date as index\n",
    "            daily_norms['latitude'] = latitude\n",
    "            daily_norms['longitude'] = longitude\n",
    "            daily_norms.set_index(['day'], inplace=True)\n",
    "\n",
    "            # TOTAL ACCUMULATION NORMS\n",
    "            # Get average accumulations through all days\n",
    "            total_norms = json_normalize(\n",
    "                agronomic_norms.get('averageAccumulations'))\n",
    "\n",
    "            # Get list of dates, add start/end dates, set date range as index\n",
    "            dates = [entry.get('day')\n",
    "                     for entry in agronomic_norms.get('dailyNorms')]\n",
    "            total_norms['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "            total_norms['start_day'] = dates[0]\n",
    "            total_norms['end_day'] = dates[-1]\n",
    "            total_norms.set_index(['date_range'], inplace=True)\n",
    "\n",
    "            # Add lat/lon\n",
    "            total_norms['latitude'] = latitude\n",
    "            total_norms['longitude'] = longitude\n",
    "\n",
    "            # Put dataframes in tuple (total norms, daily norms)\n",
    "            agronomics_df = (total_norms, daily_norms)\n",
    "\n",
    "        # Single day\n",
    "        else:\n",
    "            agronomics_df = json_normalize(agronomic_norms)\n",
    "            # agronomics_df['latitude'] = latitude\n",
    "            # agronomics_df['longitude'] = longitude\n",
    "            agronomics_df.set_index(['day'], inplace=True)\n",
    "\n",
    "        return agronomics_df\n",
    "\n",
    "    @classmethod\n",
    "    def api_to_gdf(cls, api_object, value_type='single_day', kwargs=None):\n",
    "        \"\"\"\n",
    "        value_type can be 'single_day' or 'multi_day'.\n",
    "\n",
    "        kwargs is a dictionary that provides values beyond the default;\n",
    "        unpack dictionary if it exists\n",
    "\n",
    "        kwargs are the parameters to get_data() method\n",
    "\n",
    "        kwargs={'start_day': '03-04', 'end_day': '03-07', 'offset': 2}\n",
    "        \"\"\"\n",
    "        api_data_json = api_object.get_data(\n",
    "            **kwargs) if kwargs else api_object.get_data()\n",
    "\n",
    "        if value_type.lower() == 'single_day':\n",
    "            api_data_df = cls.extract_data(api_data_json)\n",
    "\n",
    "            api_data_gdf = cls.clean_data(\n",
    "                api_data_df,\n",
    "                cls.day_coord_cols,\n",
    "                cls.day_drop_cols,\n",
    "                cls.day_rename_map\n",
    "            )\n",
    "\n",
    "        elif value_type.lower() == 'multi_day':\n",
    "            api_data_df_total, api_data_df_daily = cls.extract_data(\n",
    "                api_data_json)\n",
    "\n",
    "            api_data_gdf_total = cls.clean_data(\n",
    "                api_data_df_total,\n",
    "                cls.total_coord_cols,\n",
    "                cls.total_drop_cols,\n",
    "                cls.total_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf_daily = cls.clean_data(\n",
    "                api_data_df_daily,\n",
    "                cls.daily_coord_cols,\n",
    "                cls.daily_drop_cols,\n",
    "                cls.daily_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf = (api_data_gdf_total, api_data_gdf_daily)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value type. Please choose 'single_day' or 'multi_day'.\")\n",
    "\n",
    "        return api_data_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_field = AgronomicsFieldNorms(\n",
    "    api_key, api_secret, field_id='CO-RMNP-Bear-Lake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_field.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgronomicsFieldNorms.api_to_gdf(agro_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, daily = AgronomicsFieldNorms.api_to_gdf(agro_field, \n",
    "    value_type='multi_day', \n",
    "    kwargs={'start_day': '03-20', 'end_day': '03-25'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AgronomicsLocationValues object\n",
    "agro = AgronomicsLocationValues(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single day test (default)\n",
    "agro_json = agro.get_data()\n",
    "AgronomicsLocationValues.extract_data(agro_json)\n",
    "AgronomicsLocationValues.clean_data(\n",
    "    AgronomicsLocationValues.extract_data(agro_json),\n",
    "    AgronomicsLocationValues.day_coord_cols,\n",
    "    AgronomicsLocationValues.day_drop_cols,\n",
    "    AgronomicsLocationValues.day_rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiday test - total forecasted accumulations\n",
    "agro_json = agro.get_data(end_day='04-23')\n",
    "total_accum, daily_accum = AgronomicsLocationValues.extract_data(agro_json)\n",
    "AgronomicsLocationValues.clean_data(\n",
    "    total_accum,\n",
    "    AgronomicsLocationValues.total_coord_cols,\n",
    "    AgronomicsLocationValues.total_drop_cols,\n",
    "    AgronomicsLocationValues.total_rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi day test - dialy accumulations\n",
    "AgronomicsLocationValues.clean_data(\n",
    "    daily_accum,\n",
    "    AgronomicsLocationValues.daily_coord_cols,\n",
    "    AgronomicsLocationValues.daily_drop_cols,\n",
    "    AgronomicsLocationValues.daily_rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AgronomicsLocationValues object - single day\n",
    "agro = AgronomicsLocationValues(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)\n",
    "AgronomicsLocationValues.api_to_gdf(agro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AgronomicsLocationValues object - single day\n",
    "agro = AgronomicsLocationValues(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accum, daily_accum = AgronomicsLocationValues.api_to_gdf(\n",
    "    agro, value_type='multi_day', kwargs={'end_day': '04-23'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.today().strftime(\"%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_json = agro.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values = AgronomicsLocationValues(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values.latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single day\n",
    "agro_loc_values.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary keys\n",
    "agro_loc_values.get_data().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values.get_data(start_day='04-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattened to df\n",
    "json_normalize(agro_loc_values.get_data(start_day='04-20'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of days\n",
    "agro_loc_values.get_data(end_day='04-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values.get_data(end_day='04-24').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_day = agro_loc_values.get_data(end_day='04-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level flatten\n",
    "json_normalize(multi_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulations forecast data\n",
    "multi_day.get('accumulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulations forcast data - flattened\n",
    "json_normalize(multi_day.get('accumulations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily values forecast\n",
    "multi_day.get('dailyValues')\n",
    "\n",
    "# You have daily GDD, PET, and PPET, and \n",
    "#  accumulatd GDD, accumulated Precip, accumulated PET, and accumulated PPET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily values forecast - flattened\n",
    "json_normalize(multi_day.get('dailyValues'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have clean_data() return two things, or have two functions, like with Soil? extract_daily() vs extract_accumulated()? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference in keys - to differentiate single-day vs. multiple-day returns\n",
    "#  in the EXTRACT_DATA() function\n",
    "\n",
    "print(f\"Single day return (keys): {agro_loc_values.get_data().keys()}\")\n",
    "print(f\"Multiple day return (keys): {agro_loc_values.get_data(end_day='04-24').keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to treat single day vs multiple day returns differently\n",
    "# Don't drop columns during this phase, bc of differences in single vs multi\n",
    "# Create options/parameters for 'daily' vs 'total' for accumulations in the api_to_gdf(),\n",
    "#  similar to the 'main' vs. 'soil'. This will allow to extract the total accumlated (forecast) values\n",
    "#  in one dataframe vs. the daily accumulations (forecast) in another dataframe.\n",
    "# It would be useful/necessary to have a start_date and end_date into the total accumulations data;\n",
    "#  can these be taken from the parameters? How to incorporate this data into the DF?\n",
    "#  Make list of dates, take first list[0] and last list[-1], and make new columns for this\n",
    "\n",
    "#for entry in multi_day.get('dailyValues'):\n",
    "    #print(entry.get('date'))\n",
    "    \n",
    "dates = [entry.get('date') for entry in multi_day.get('dailyValues')]\n",
    "\n",
    "dates[0]\n",
    "dates[-1]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_loc_values = AgronomicsLocationValues(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function testing - DAILY VALUES\n",
    "agronomics_total_accumulation = None\n",
    "agronomics_daily_accumulation_iterator = None\n",
    "agronomics = None\n",
    "#agronomics = agro_loc_values.get_data() # Single day\n",
    "# There can be a mismatch between the total accumulations \n",
    "#  and the sume of daily accumulations IF you specify more\n",
    "#  than 10 days. The get_data function will return 10 day limit\n",
    "#  for the daily accumulations, but the total accumulations will\n",
    "#  go out to 15 days if specified for more than 10.\n",
    "agronomics = agro_loc_values.get_data(end_day='04-23')  # Multi-day\n",
    "\n",
    "latitude = agronomics.get('location').get('latitude')\n",
    "longitude = agronomics.get('location').get('longitude')\n",
    "\n",
    "# Check if more than one day\n",
    "if agronomics.get('dailyValues'):\n",
    "\n",
    "    # Do these with a separate call, just like in Soil accumulation='daily'\n",
    "    #  accumulation='total'\n",
    "\n",
    "    # Daily forecasted accumulations for each day\n",
    "    agronomics_daily_accumulation = json_normalize(\n",
    "        agronomics.get('dailyValues'))\n",
    "    agronomics_daily_accumulation['latitude'] = latitude\n",
    "    agronomics_daily_accumulation['longitude'] = longitude\n",
    "    agronomics_daily_accumulation.set_index(['date'], inplace=True)\n",
    "\n",
    "    # Add lat/lon\n",
    "    # Shorten depth values to numerics (will be used in MultiIndex)\n",
    "#     forecast_soil_df['depth'] = forecast_soil_df['depth'].apply(\n",
    "#         lambda x: x[0:-15])\n",
    "\n",
    "    # Total forecasted accumulations through all days\n",
    "    agronomics_total_accumulation = json_normalize(\n",
    "        agronomics.get('accumulations'))\n",
    "    dates = [entry.get('date') for entry in agronomics.get('dailyValues')]\n",
    "    agronomics_total_accumulation['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "    agronomics_total_accumulation['start_day'] = dates[0]\n",
    "    agronomics_total_accumulation['end_day'] = dates[-1]\n",
    "    agronomics_total_accumulation['latitude'] = latitude\n",
    "    agronomics_total_accumulation['longitude'] = longitude\n",
    "    agronomics_total_accumulation.set_index(['date_range'], inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "# Single day\n",
    "else:\n",
    "    agronomics_iterator = json_normalize(agronomics)\n",
    "    agronomics_iterator['latitude'] = latitude\n",
    "    agronomics_iterator['longitude'] = longitude\n",
    "    agronomics_iterator.set_index(['date'], inplace=True)\n",
    "\n",
    "# agronomics_iterator\n",
    "#agronomics_daily_accumulation\n",
    "#agronomics_total_accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function testing - DAILY VALUES\n",
    "agronomics = agro_loc_values.get_data()\n",
    "agronomics = agro_loc_values.get_data(end_day='04-24')\n",
    "\n",
    "# Check if more than one day\n",
    "if agronomics.get('dailyValues'):\n",
    "    agronomics_iterator = json_normalize(agronomics.get('dailyValues'))\n",
    "\n",
    "# Single day\n",
    "else:\n",
    "    agronomics_iterator = json_normalize(agronomics)\n",
    "\n",
    "        \n",
    "agronomics_iterator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4: Sub-sub-sub-class - AgronomicsLocationNorms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API URL: https://api.awhere.com/v2/agronomics/locations/{latitude},{longitude}/agronomicnorms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsLocationNorms(AgronomicsLocation):\n",
    "\n",
    "    # Class variables for clean_data() function\n",
    "    \n",
    "    # https://developer.awhere.com/api/reference/agronomics/norms/geolocation\n",
    "    \n",
    "    \"\"\"The average ratio of Precipitation to Potential Evapotranspiration \n",
    "    over the years specified. When this value is above 1, then more rain fell \n",
    "    than the amount of likely water loss; if it's below 1, then more water was\n",
    "    likely lost than fell as rain. P/PET is most useful when calculated for a \n",
    "    range of days, as it is for this property, than for individual days.\"\"\"\n",
    "    \n",
    "    # Single day   \n",
    "    day_coord_cols = ['location.latitude', 'location.longitude']\n",
    "\n",
    "    day_drop_cols = ['pet.units', '_links.self.href']\n",
    "\n",
    "    day_rename_map = {\n",
    "        \"gdd.average\": \"gdd_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"gdd_average_total_std_dev_cels\",\n",
    "        \"pet.average\": \"pet_average_total_mm\",\n",
    "        \"pet.stdDev\": \"pet_average_total_std_dev_mm\",\n",
    "        \"ppet.average\": \"ppet_average\",\n",
    "        \"ppet.stdDev\": \"ppet_average_std_dev\"\n",
    "    }\n",
    "     \n",
    "    # Multi-day, total accumulation\n",
    "    total_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    total_drop_cols = ['precipitation.units', 'pet.units']\n",
    "\n",
    "    total_rename_map = {\n",
    "        \"gdd.average\": \"norms_gdd_average_total_cels\",\n",
    "        \"gdd.stdDev\": \"norms_gdd_average_total_std_dev_cels\",\n",
    "        \"precipitation.average\": \"norms_precip_average_total_mm\",\n",
    "        \"precipitation.stdDev\": \"norms_precip_average_total_std_dev_mm\",\n",
    "        \"pet.average\": \"norms_pet_average_total_mm\",\n",
    "        \"pet.stdDev\": \"norms_pet_average_total_std_dev\",\n",
    "        \"ppet.average\": \"norms_ppet_average_total\",\n",
    "        \"ppet.stdDev\": \"norms_ppet_average_total_std_dev\"\n",
    "    }\n",
    "\n",
    "    # Multi-day, daily accumulation\n",
    "    daily_coord_cols = ['latitude', 'longitude']\n",
    "\n",
    "    daily_drop_cols = ['pet.units', 'accumulatedPrecipitation.units',\n",
    "                       'accumulatedPet.units', '_links.self.href']\n",
    "\n",
    "    daily_rename_map = {       \n",
    "        \"gdd.average\": \"norms_gdd_average_daily_cels\",\n",
    "        \"gdd.stdDev\": \"norms_gdd_average_daily_std_dev_cels\",\n",
    "        \"pet.average\": \"norms_pet_average_daily_mm\",\n",
    "        \"pet.stdDev\": \"norms_pet_average_daily_std_dev_mm\",\n",
    "        \"ppet.average\": \"norms_ppet_average_daily\",\n",
    "        \"ppet.stdDev\": \"norms_ppet_average_daily_std_dev\",\n",
    "        \"accumulatedGdd.average\": \"norms_gdd_average_rolling_accum\",\n",
    "        \"accumulatedGdd.stdDev\": \"norms_gdd_average_rolling_accum_std_dev\",\n",
    "        \"accumulatedPrecipitation.average\": \"norms_precip_average_rolling_accum_mm\",\n",
    "        \"accumulatedPrecipitation.stdDev\": \"norms_precip_average_rolling_accum_std_dev_mm\",\n",
    "        \"accumulatedPet.average\": \"norms_pet_average_rolling_accum_mm\",\n",
    "        \"accumulatedPet.stdDev\": \"norms_pet_average_rolling_accum_std_dev_mm\", \n",
    "        \"accumulatedPpet.average\": \"norms_ppet_average_rolling_accum\",\n",
    "        \"accumulatedPpet.stdDev\": \"norms_ppet_average_rolling_accum_std\"\n",
    "    }\n",
    "\n",
    "    # Define lat/lon when intitializing class; no need to repeat for lat/lon\n",
    "    #  in get_data() because it is already programmed into api_url\n",
    "    def __init__(self, api_key, api_secret, latitude, longitude, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsLocationNorms, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.api_url = f\"{self.api_url}/{self.latitude},{self.longitude}/agronomicnorms\"\n",
    "\n",
    "    def get_data(self, start_day='01-01', end_day=None, offset=0):\n",
    "        \"\"\"Returns aWhere Historic Agronomic Norms.\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Perform the HTTP request to obtain the norms for the Field\n",
    "        # Define URL variants\n",
    "        url_single_day = f\"{self.api_url}/{start_day}\"\n",
    "        url_multiple_days = f\"{self.api_url}/{start_day},{end_day}?limit=10&offset={offset}\"\n",
    "\n",
    "        # Get single day norms or date range\n",
    "        response = requests.get(url_multiple_days, headers=auth_headers) if end_day else requests.get(\n",
    "            url_single_day, headers=auth_headers)\n",
    "\n",
    "        # Return the norms\n",
    "        return response.json()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_data(agronomic_norms):\n",
    "        \"\"\"Extracts data from the aWhere agronomic norms\n",
    "        data in JSON format.\n",
    "        \"\"\"\n",
    "        # Extract lat/lon\n",
    "        latitude = agronomic_norms.get('location').get('latitude')\n",
    "        longitude = agronomic_norms.get('location').get('longitude')\n",
    "\n",
    "        # Check if more than one day\n",
    "        if agronomic_norms.get('dailyNorms'):\n",
    "\n",
    "            # DAILY ACCUMULATION NORMS\n",
    "            # Get daily accumulation norms\n",
    "            daily_norms = json_normalize(\n",
    "                agronomic_norms.get('dailyNorms'))\n",
    "\n",
    "            # Add lat/lon and set date as index\n",
    "            daily_norms['latitude'] = latitude\n",
    "            daily_norms['longitude'] = longitude\n",
    "            daily_norms.set_index(['day'], inplace=True)\n",
    "\n",
    "            # TOTAL ACCUMULATION NORMS\n",
    "            # Get average accumulations through all days\n",
    "            total_norms = json_normalize(\n",
    "                agronomic_norms.get('averageAccumulations'))\n",
    "\n",
    "            # Get list of dates, add start/end dates, set date range as index\n",
    "            dates = [entry.get('day')\n",
    "                     for entry in agronomic_norms.get('dailyNorms')]\n",
    "            total_norms['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "            total_norms['start_day'] = dates[0]\n",
    "            total_norms['end_day'] = dates[-1]\n",
    "            total_norms.set_index(['date_range'], inplace=True)\n",
    "\n",
    "            # Add lat/lon\n",
    "            total_norms['latitude'] = latitude\n",
    "            total_norms['longitude'] = longitude\n",
    "\n",
    "            # Put dataframes in tuple (total norms, daily norms)\n",
    "            agronomics_df = (total_norms, daily_norms)\n",
    "\n",
    "        # Single day\n",
    "        else:\n",
    "            agronomics_df = json_normalize(agronomic_norms)\n",
    "            # agronomics_df['latitude'] = latitude\n",
    "            # agronomics_df['longitude'] = longitude\n",
    "            agronomics_df.set_index(['day'], inplace=True)\n",
    "\n",
    "        return agronomics_df\n",
    "\n",
    "    @classmethod\n",
    "    def api_to_gdf(cls, api_object, value_type='single_day', kwargs=None):\n",
    "        \"\"\"\n",
    "        value_type can be 'single_day' or 'multi_day'.\n",
    "\n",
    "        kwargs is a dictionary that provides values beyond the default;\n",
    "        unpack dictionary if it exists\n",
    "\n",
    "        kwargs are the parameters to get_data() method\n",
    "\n",
    "        kwargs={'start_day': '03-04', 'end_day': '03-07', 'offset': 2}\n",
    "        \"\"\"\n",
    "        api_data_json = api_object.get_data(\n",
    "            **kwargs) if kwargs else api_object.get_data()\n",
    "\n",
    "        if value_type.lower() == 'single_day':\n",
    "            api_data_df = cls.extract_data(api_data_json)\n",
    "\n",
    "            api_data_gdf = cls.clean_data(\n",
    "                api_data_df,\n",
    "                cls.day_coord_cols,\n",
    "                cls.day_drop_cols,\n",
    "                cls.day_rename_map\n",
    "            )\n",
    "\n",
    "        elif value_type.lower() == 'multi_day':\n",
    "            api_data_df_total, api_data_df_daily = cls.extract_data(\n",
    "                api_data_json)\n",
    "\n",
    "            api_data_gdf_total = cls.clean_data(\n",
    "                api_data_df_total,\n",
    "                cls.total_coord_cols,\n",
    "                cls.total_drop_cols,\n",
    "                cls.total_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf_daily = cls.clean_data(\n",
    "                api_data_df_daily,\n",
    "                cls.daily_coord_cols,\n",
    "                cls.daily_drop_cols,\n",
    "                cls.daily_rename_map\n",
    "            )\n",
    "\n",
    "            api_data_gdf = (api_data_gdf_total, api_data_gdf_daily)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value type. Please choose 'single_day' or 'multi_day'.\")\n",
    "\n",
    "        return api_data_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AgronomicsLocationNorms object - single day\n",
    "agro = AgronomicsLocationNorms(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = AgronomicsLocationNorms.api_to_gdf(\n",
    "    agro, value_type='single_day', kwargs={'start_day': '05-05'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accum, daily_accum = AgronomicsLocationNorms.api_to_gdf(\n",
    "    agro, value_type='multi_day', kwargs={'start_day': '05-05', 'end_day': '05-14'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_norms = AgronomicsLocationNorms(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_norms.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single day agronomic norms\n",
    "agro_norms.get_data(start_day='05-05')#.get('location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_norms.get_data(start_day='05-05', end_day='05-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi day agronomic norms - average accums in this period\n",
    "json_normalize(agro_norms.get_data(start_day='05-05', end_day='05-14').get('averageAccumulations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi day agronomic norms - daily accums in this period\n",
    "json_normalize(agro_norms.get_data(start_day='05-05', end_day='05-14').get('dailyNorms')).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_norms = AgronomicsLocationNorms(\n",
    "    api_key, api_secret, latitude=40.313250, longitude=-105.648222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agronomic_norms = agro_norms.get_data(start_day='05-05')\n",
    "day = AgronomicsLocationNorms.extract_data(agronomic_norms)\n",
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agronomic_norms = agro_norms.get_data(start_day='05-05', end_day='05-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, daily = AgronomicsLocationNorms.extract_data(agronomic_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract lat/lon\n",
    "latitude = agronomic_norms.get('location').get('latitude')\n",
    "longitude = agronomic_norms.get('location').get('longitude')\n",
    "\n",
    "# Check if more than one day\n",
    "if agronomic_norms.get('dailyNorms'):\n",
    "\n",
    "    # DAILY ACCUMULATION NORMS\n",
    "    # Get daily accumulation norms\n",
    "    daily_norms = json_normalize(\n",
    "        agronomic_norms.get('dailyNorms'))\n",
    "\n",
    "    # Add lat/lon and set date as index\n",
    "    daily_norms['latitude'] = latitude\n",
    "    daily_norms['longitude'] = longitude\n",
    "    daily_norms.set_index(['day'], inplace=True)\n",
    "\n",
    "    # TOTAL ACCUMULATION NORMS\n",
    "    # Get average accumulations through all days\n",
    "    total_norms = json_normalize(\n",
    "        agronomic_norms.get('averageAccumulations'))\n",
    "\n",
    "    # Get list of dates, add start/end dates, set date range as index\n",
    "    dates = [entry.get('day')\n",
    "             for entry in agronomic_norms.get('dailyNorms')]\n",
    "    total_norms['date_range'] = f\"{dates[0]}/{dates[-1]}\"\n",
    "    total_norms['start_day'] = dates[0]\n",
    "    total_norms['end_day'] = dates[-1]\n",
    "    total_norms.set_index(['date_range'], inplace=True)\n",
    "\n",
    "    # Add lat/lon\n",
    "    total_norms['latitude'] = latitude\n",
    "    total_norms['longitude'] = longitude\n",
    "\n",
    "    # Put dataframes in tuple (total norms, daily norms)\n",
    "    agronomics_df = (total_norms, daily_norms)\n",
    "\n",
    "# Single day\n",
    "else:\n",
    "    agronomics_df = json_normalize(agronomic_norms)\n",
    "    # agronomics_df['latitude'] = latitude\n",
    "    # agronomics_df['longitude'] = longitude\n",
    "    agronomics_df.set_index(['day'], inplace=True)\n",
    "\n",
    "return agronomics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, daily = agronomics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsCrops(Agronomics):\n",
    "\n",
    "    def __init__(self, api_key, api_secret, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsCrops, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.api_url = f\"{self.api_url}/crops\"\n",
    "\n",
    "    # field_id=None, crop_name=None, limit=10, offset=0\n",
    "    def get(self, crop_id=None, limit=10, offset=0):\n",
    "        \"\"\"Retrieve a list of available crops.\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Get API response, single crop or page of crops\n",
    "        response = requests.get(f\"{self.api_url}/{crop_id}\", headers=auth_headers) if crop_id else requests.get(\n",
    "            f\"{self.api_url}?limit={limit}&offset={offset}\", headers=auth_headers)\n",
    "\n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Conveer to dataframe\n",
    "        response_df = json_normalize(response_json) if crop_id else json_normalize(\n",
    "            response_json.get('crops'))\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        response_df.drop(columns=[\n",
    "            '_links.self.href', '_links.curies', '_links.awhere:plantings.href'\n",
    "        ], inplace=True)\n",
    "\n",
    "        # Reset index\n",
    "        response_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Define new column names\n",
    "        crop_rename = {\n",
    "            'id': 'crop_id',\n",
    "            'name': 'crop_name',\n",
    "            'type': 'crop_type',\n",
    "            'variety': 'crop_variety',\n",
    "            'isDefaultForCrop': 'default_crop'\n",
    "        }\n",
    "\n",
    "        # Rename columns\n",
    "        response_df.rename(columns=crop_rename, inplace=True)\n",
    "\n",
    "        return response_df\n",
    "\n",
    "    def get_full(self, limit=10, offset=0, max_pages=3):\n",
    "        \"\"\"Retrieves the full list of available crops,\n",
    "        based on limit, offset, and max pages.\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Define list to store page dataframes\n",
    "        response_df_list = []\n",
    "\n",
    "        # Loop through all pages\n",
    "        while offset < limit * max_pages:\n",
    "\n",
    "            # Get API response; convert response to dataframe; append to dataframe list\n",
    "            response = requests.get(\n",
    "                f\"{self.api_url}?limit={limit}&offset={offset}\", headers=auth_headers)\n",
    "            response_json = response.json()\n",
    "            response_df_loop = json_normalize(response_json.get('crops'))\n",
    "            response_df_list.append(response_df_loop)\n",
    "            offset += 10\n",
    "\n",
    "        # Merge all dataframes into a single dataframe\n",
    "        response_df = pd.concat(response_df_list, axis=0)\n",
    "\n",
    "        # Drop unnecessary dataframe columns\n",
    "        response_df.drop(columns=[\n",
    "            '_links.self.href', '_links.curies', '_links.awhere:plantings.href'\n",
    "        ], inplace=True)\n",
    "\n",
    "        # Reset dataframe index\n",
    "        response_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Define new column name mapping\n",
    "        crop_rename = {\n",
    "            'id': 'crop_id',\n",
    "            'name': 'crop_name',\n",
    "            'type': 'crop_type',\n",
    "            'variety': 'crop_variety',\n",
    "            'isDefaultForCrop': 'default_crop'\n",
    "        }\n",
    "\n",
    "        # Rename dataframe columns\n",
    "        response_df.rename(columns=crop_rename, inplace=True)\n",
    "\n",
    "        return response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AgronomicsCrops(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get(crop_id='canola-b-rapa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = a.get_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get().get('next', 'Wrong level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(a.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(a.get().get('crops'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsCrop(AgronomicsCrops):\n",
    "\n",
    "    def __init__(self, api_key, api_secret, crop_id, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsCrop, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.api_url = f\"{self.api_url}/{crop_id}\"\n",
    "        \n",
    "    def get(self):\n",
    "        \"\"\"Retrieves the information for the defined crop.\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Get API response, single crop\n",
    "        response = requests.get(f\"{self.api_url}\", headers=auth_headers)\n",
    "    \n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Conveer to dataframe\n",
    "        response_df = json_normalize(response_json)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        response_df.drop(columns=[\n",
    "            '_links.self.href', '_links.curies', '_links.awhere:plantings.href'\n",
    "        ], inplace=True)\n",
    "\n",
    "        # Reset index\n",
    "        response_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Define new column names\n",
    "        crop_rename = {\n",
    "            'id': 'crop_id',\n",
    "            'name': 'crop_name',\n",
    "            'type': 'crop_type',\n",
    "            'variety': 'crop_variety',\n",
    "            'isDefaultForCrop': 'default_crop'\n",
    "        }\n",
    "\n",
    "        # Rename columns\n",
    "        response_df.rename(columns=crop_rename, inplace=True)\n",
    "\n",
    "        return response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AgronomicsCrop(api_key, api_secret, 'corn-2300-gdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsFieldPlantings(AgronomicsField):\n",
    "\n",
    "    # Define field_id intitializing class\n",
    "    def __init__(self, api_key, api_secret, field_id, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsFieldPlantings, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.field_id = field_id\n",
    "        self.api_url = f\"{self.api_url}/{self.field_id}/plantings\"\n",
    "\n",
    "    def get(self, planting_id=None, limit=10, offset=0):\n",
    "        \"\"\"Returns aWhere plantings associated with a specified field.\n",
    "\n",
    "        planting_id can either be an actual id or 'current' for the most\n",
    "        current planting. 'None' will result in all plantings\n",
    "\n",
    "        GET /v2/agronomics/fields/{fieldId}/plantings\n",
    "        GET /v2/agronomics/fields/{fieldId}/plantings/{plantingId}\n",
    "        GET /v2/agronomics/fields/{fieldId}/plantings/current        \n",
    "        \"\"\"\n",
    "\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "            # \"Content-Type\": 'application/json'\n",
    "        }\n",
    "\n",
    "        # Get API response\n",
    "        response = requests.get(f\"{self.api_url}/{planting_id}\", headers=auth_headers) if planting_id else requests.get(\n",
    "            f\"{self.api_url}?limit={limit}&offset={offset}\", headers=auth_headers)\n",
    "        \n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Convert to dataframe\n",
    "        response_df = json_normalize(response_json) if planting_id else json_normalize(\n",
    "            response_json.get('plantings'))\n",
    "\n",
    "        drop_cols = [\n",
    "            '_links.self.href', '_links.curies', \n",
    "            '_links.awhere:crop.href', '_links.awhere:field.href'\n",
    "        ]\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        response_df.drop(\n",
    "            columns=drop_cols, inplace=True)\n",
    "            \n",
    "        # Define new column names\n",
    "        planting_rename = {\n",
    "            'id': 'planting_id',\n",
    "            'crop': 'crop_id',\n",
    "            'field': 'field_id',\n",
    "            'plantingDate': 'planting_date',\n",
    "            'harvestDate': 'harvest_date_actual',\n",
    "            # What is 'recommendation' field? What output goes here, and where does it come from?\n",
    "            'yield.amount': 'yield_amount_actual', #{response_json.get(\"yield\").get(\"units\").lower()}',\n",
    "            'yield.units': 'yield_amount_actual_units',\n",
    "            'projections.yield.amount': 'yield_amount_projected', #{response_json.get(\"projections\").get(\"yield\").get(\"units\").lower()}',\n",
    "            'projections.yield.units': 'yield_amount_projected_units',\n",
    "            'projections.harvestDate': 'harvest_date_projected' \n",
    "        }\n",
    "\n",
    "        # Rename\n",
    "        response_df.rename(columns=planting_rename, inplace=True)\n",
    "\n",
    "        # Set index\n",
    "        response_df.set_index('planting_id', inplace=True)\n",
    "        \n",
    "        return response_df\n",
    "\n",
    "    def create(self, crop, planting_date, projected_yield_amount=None, projected_yield_units=None,\n",
    "               projected_harvest_date=None, yield_amount=None, yield_units=None, harvest_date=None):\n",
    "        \"\"\"Creates a planting in the field.\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {str(self.auth_token)}\",\n",
    "            \"Content-Type\": 'application/json'\n",
    "        }\n",
    "\n",
    "        # Define request body\n",
    "        field_body = {\n",
    "            \"crop\": crop,\n",
    "            \"plantingDate\": planting_date,\n",
    "            \"projections\": {\n",
    "                \"yield\": {\n",
    "                    \"amount\": projected_yield_amount,\n",
    "                    \"units\": projected_yield_units,\n",
    "                },\n",
    "                \"harvestDate\": projected_harvest_date\n",
    "            },\n",
    "            \"yield\": {\n",
    "                \"amount\": yield_amount,\n",
    "                \"units\": yield_units,\n",
    "            },\n",
    "            \"harvestDate\": harvest_date\n",
    "        }\n",
    "        \n",
    "        # Creat planting\n",
    "        response = requests.post(\n",
    "            self.api_url, headers=auth_headers, json=field_body)\n",
    "\n",
    "        return response.json()\n",
    "\n",
    "    def update(self, planting_id='current', update_type='replace', kwargs=None):\n",
    "        \"\"\"Update a planting. update_type can be 'replace' or 'update'\n",
    "        \n",
    "        kwargs is a dict with all the update values\n",
    "        \n",
    "        PUT /v2/agronomics/fields/{fieldId}/plantings/{plantingId}\n",
    "        PUT /v2/agronomics/fields/{fieldId}/plantings/current\n",
    "        \n",
    "        update_kwargs = {\n",
    "            \"crop\": 'wheat-hardred',\n",
    "            \"planting_date\": '2019-05-20', \n",
    "            \"projected_yield_amount\": 90, \n",
    "            \"projected_yield_units\": 'small boxes',\n",
    "            \"projected_harvest_date\": \"2019-08-10\", \n",
    "            \"yield_amount\": 100, \n",
    "            \"yield_units\": \"medium boxes\", \n",
    "            \"harvest_date\": '2019-08-31'\n",
    "        }\n",
    "    \n",
    "        PATCH /v2/agronomics/fields/{fieldId}/plantings/{plantingId}\n",
    "        PATCH /v2/agronomics/fields/{fieldId}/plantings/current\n",
    "        \n",
    "        Use dict comprehension for updates\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {str(self.auth_token)}\",\n",
    "            \"Content-Type\": 'application/json'\n",
    "        }   \n",
    "    \n",
    "        # Full replace\n",
    "        if update_type.lower() == 'replace':\n",
    "        # Define request body\n",
    "            field_body = {\n",
    "                \"crop\": kwargs.get('crop'),\n",
    "                \"plantingDate\": kwargs.get('planting_date'),\n",
    "                \"projections\": {\n",
    "                    \"yield\": {\n",
    "                        \"amount\": kwargs.get('projected_yield_amount'),\n",
    "                        \"units\": kwargs.get('projected_yield_units'),\n",
    "                    },\n",
    "                    \"harvestDate\": kwargs.get('projected_harvest_date')\n",
    "                },\n",
    "                \"yield\": {\n",
    "                    \"amount\": kwargs.get('yield_amount'),\n",
    "                    \"units\": kwargs.get('yield_units'),\n",
    "                },\n",
    "                \"harvestDate\": kwargs.get('harvest_date')\n",
    "            }\n",
    "        \n",
    "            # Update planting\n",
    "            response = requests.put(\n",
    "                f\"{self.api_url}/{planting_id}\", headers=auth_headers, json=field_body)\n",
    "            \n",
    "        elif update_type.lower() == 'update':\n",
    "            \n",
    "            # Define field body\n",
    "            field_body = [{\"op\": \"replace\", \"path\": f\"/{key}\", \"value\": f\"{value}\"}\n",
    "                         for key, value in kwargs.items()]\n",
    "            \n",
    "            # Perform the HTTP request to update field information\n",
    "            response = requests.patch(\n",
    "                f\"{self.api_url}/{planting_id}\", headers=auth_headers, json=field_body)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid update type. Please choose 'replace' or 'update'.\")\n",
    "\n",
    "        return response.json()\n",
    "        \n",
    "    def delete(self, planting_id='current'):\n",
    "        \"\"\"Deletes a planting, based on planting id or\n",
    "        the most recent planting (based on id)\n",
    "        \"\"\"\n",
    "         # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\",\n",
    "            #\"Content-Type\": 'application/json'\n",
    "        }\n",
    "\n",
    "        # Perform the POST request to Delete the Field\n",
    "        response = requests.delete(\n",
    "            f\"{self.api_url}/{planting_id}\", headers=auth_headers)\n",
    "\n",
    "        message = f\"Deleted planting: {planting_id}\" if response.status_code == 204 else f\"Could not delete planting.\"\n",
    "\n",
    "        return print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Define request body\n",
    "#             field_body = [{\n",
    "#                 \"op\": \"replace\",\n",
    "#                 \"path\": f\"/{key}\",\n",
    "#                 \"value\": f\"{value}\"\n",
    "#             } for key:value in kwargs]\n",
    "           \n",
    "dict_list = []\n",
    "for key, value in update_kwargs.items():\n",
    "    new_dict = {\n",
    "        \"op\": \"replace\",\n",
    "        \"path\": f\"/{key}\",\n",
    "        \"value\": f\"{value}\"\n",
    "    }\n",
    "    dict_list.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_comp = [{\"op\": \"replace\", \"path\": f\"/{key}\", \"value\": f\"{value}\"}\n",
    "                  for key, value in update_kwargs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object = AgronomicsFieldPlantings(\n",
    "    api_key, api_secret, 'CO-RMNP-Bear-Lake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_kwargs = {\n",
    "    \"crop\": 'wheat-hardred',\n",
    "    \"planting_date\": '2019-05-20', \n",
    "    \"projected_yield_amount\": 90, \n",
    "    \"projected_yield_units\": 'small boxes',\n",
    "    \"projected_harvest_date\": \"2019-08-10\", \n",
    "    \"yield_amount\": 100, \n",
    "    \"yield_units\": \"medium boxes\", \n",
    "    \"harvest_date\": '2019-08-31'\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object.update(update_type='update', kwargs=update_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planting = plantings_object.create(\n",
    "    crop='sorghum-long-season', planting_date='2019-05-05', \n",
    "    projected_yield_amount=80, projected_yield_units='boxes',\n",
    "    yield_amount=75, yield_units='boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plantings_object.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object.delete(464536787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, json = plantings_object.get(planting_id='current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.get('projections').get('yield').get('units').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(json.get('projections').get('yield').get('units')).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(json.get('yield').get('units')).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plantings_object.get(planting_id='current') # most recent (based on id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object.get(planting_id=464533) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantings_object.field_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(plantings_object.get().get('plantings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planting = plantings_object.create(crop='wheat-hardred', planting_date='2019-05-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(planting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AgronomicsFieldPlanting(AgronomicsField):\n",
    "\n",
    "#     # Define field_id intitializing class\n",
    "#     def __init__(self, api_key, api_secret, field_id, planting_id, base_64_encoded_secret_key=None,\n",
    "#                  auth_token=None, api_url=None):\n",
    "        \n",
    "#         \"\"\"planting_id can either be 'current' or the specific planting_id for a field\n",
    "#         \"\"\"\n",
    "#         super(AgronomicsFieldPlanting, self).__init__(\n",
    "#             api_key, api_secret, base_64_encoded_secret_key, auth_token, field_id)\n",
    "\n",
    "#         self.field_id = field_id\n",
    "#         self.api_url = f\"{self.api_url}\"#\"/{self.field_id}/plantings/{planting_id}\"\n",
    "        \n",
    "        \n",
    "#     def get(self):\n",
    "#         \"\"\"Retrieve info about the planting.\n",
    "#         \"\"\"\n",
    "#         # Setup the HTTP request headers\n",
    "#         auth_headers = {\n",
    "#             \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "#             # \"Content-Type\": 'application/json'\n",
    "#         }\n",
    "\n",
    "#         # Get API response\n",
    "#         response = requests.get(f\"{self.api_url}\", headers=auth_headers) \n",
    "        \n",
    "#         # Convert API response to JSON format\n",
    "#         response_json = response.json()\n",
    "\n",
    "# #         # Convert to dataframe\n",
    "# #         response_df = json_normalize(response_json)\n",
    "\n",
    "# #         drop_cols = [\n",
    "# #             '_links.self.href', '_links.curies', \n",
    "# #             '_links.awhere:crop.href', '_links.awhere:field.href'\n",
    "# #         ]\n",
    "        \n",
    "# #         # Drop unnecessary columns\n",
    "# # #         response_df.drop(\n",
    "# # #             columns=drop_cols, inplace=True)\n",
    "            \n",
    "# #         # Define new column names\n",
    "# #         planting_rename = {\n",
    "# #             'id': 'planting_id',\n",
    "# #             'crop': 'crop_id',\n",
    "# #             'field': 'field_id',\n",
    "# #             'plantingDate': 'planting_date',\n",
    "# #             'harvestDate': 'harvest_date_actual',\n",
    "# #             # What is 'recommendation' field? What output goes here, and where does it come from?\n",
    "# #             'yield.amount': 'yield_amount_actual', #{response_json.get(\"yield\").get(\"units\").lower()}',\n",
    "# #             'yield.units': 'yield_amount_actual_units',\n",
    "# #             'projections.yield.amount': 'yield_amount_projected', #{response_json.get(\"projections\").get(\"yield\").get(\"units\").lower()}',\n",
    "# #             'projections.yield.units': 'yield_amount_projected_units',\n",
    "# #             'projections.harvestDate': 'harvest_date_projected' \n",
    "# #         }\n",
    "\n",
    "# #         # Rename\n",
    "# #         response_df.rename(columns=planting_rename, inplace=True)\n",
    "\n",
    "# #         # Set index\n",
    "# #         response_df.set_index('planting_id', inplace=True)\n",
    "        \n",
    "#         return response_json\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = AgronomicsFieldPlanting(\n",
    "    api_key, api_secret, field_id='CO-RMNP-Bear-Lake', planting_id='current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planting_object = AgronomicsFieldPlanting(\n",
    "    api_key, api_secret, field_id='CO-RMNP-Bear-Lake', planting_id=464536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planting_object.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planting_object.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Planting(AgronomicsFieldPlantings):\n",
    "\n",
    "    # Define field_id intitializing class\n",
    "    def __init__(self, api_key, api_secret, field_id, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(Planting, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.field_id = field_id\n",
    "        #self.api_url = f\"{self.api_url}/{self.field_id}/plantings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Planting(api_key, api_secret, field_id='RMNP-CO-Bear-Lake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsModels(Agronomics):\n",
    "\n",
    "    def __init__(self, api_key, api_secret, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsModels, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.api_url = f\"{self.api_url}/models\"\n",
    "\n",
    "    def get(self, model_id=None, limit=10, offset=0):\n",
    "        \"\"\"Retrieve a list of available models.\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Get API response, single crop or page of crops\n",
    "        response = requests.get(f\"{self.api_url}/{model_id}\", headers=auth_headers) if model_id else requests.get(\n",
    "            f\"{self.api_url}?limit={limit}&offset={offset}\", headers=auth_headers)\n",
    "\n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Convert to dataframe\n",
    "        response_df = json_normalize(response_json) if model_id else json_normalize(\n",
    "            response_json.get('models'))\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        response_df.drop(columns=[\n",
    "            '_links.self.href', '_links.curies', \n",
    "            '_links.awhere:crop', '_links.awhere:modelDetails.href'\n",
    "        ], inplace=True)\n",
    "\n",
    "        # Define new column names\n",
    "        model_rename = {\n",
    "            'id': 'model_id',\n",
    "            'name': 'model_name',\n",
    "            'description': 'model_description',\n",
    "            'type': 'model_type',\n",
    "            'source.name': 'model_source',\n",
    "            'source.link': 'model_link'\n",
    "        }\n",
    "\n",
    "        # Rename columns\n",
    "        response_df.rename(columns=model_rename, inplace=True)\n",
    "\n",
    "        # Set index\n",
    "        response_df.set_index('model_id', inplace=True)\n",
    "\n",
    "        return response_df\n",
    "\n",
    "    def get_full(self, limit=10, offset=0, max_pages=3):\n",
    "        \"\"\"Retrieves the full list of available models,\n",
    "        based on limit, offset, and max pages.\n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Define list to store page dataframes\n",
    "        response_df_list = []\n",
    "\n",
    "        # Loop through all pages\n",
    "        while offset < limit * max_pages:\n",
    "\n",
    "            # Get API response; convert response to dataframe; append to dataframe list\n",
    "            response = requests.get(\n",
    "                f\"{self.api_url}?limit={limit}&offset={offset}\", headers=auth_headers)\n",
    "            response_json = response.json()\n",
    "            response_df_loop = json_normalize(response_json.get('models'))\n",
    "            response_df_list.append(response_df_loop)\n",
    "            offset += 10\n",
    "\n",
    "        # Merge all dataframes into a single dataframe\n",
    "        response_df = pd.concat(response_df_list, axis=0)\n",
    "        \n",
    "          # Drop unnecessary columns\n",
    "        response_df.drop(columns=[\n",
    "            '_links.self.href', '_links.curies', \n",
    "            '_links.awhere:crop', '_links.awhere:modelDetails.href'\n",
    "        ], inplace=True)\n",
    "\n",
    "        # Define new column names\n",
    "        model_rename = {\n",
    "            'id': 'model_id',\n",
    "            'name': 'model_name',\n",
    "            'description': 'model_description',\n",
    "            'type': 'model_type',\n",
    "            'source.name': 'model_source',\n",
    "            'source.link': 'model_link'\n",
    "        }\n",
    "\n",
    "        # Rename columns\n",
    "        response_df.rename(columns=model_rename, inplace=True)\n",
    "\n",
    "        # Set index\n",
    "        response_df.set_index('model_id', inplace=True)\n",
    "\n",
    "        return response_df\n",
    "    \n",
    "    \n",
    "    def get_details(self, model_id='BarleyGenericMSU'):\n",
    "        \"\"\"Retrieve model details\n",
    "        \"\"\"\n",
    "         # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "        }\n",
    "\n",
    "        # Get API response, single crop or page of crops\n",
    "        response = requests.get(f\"{self.api_url}/{model_id}/details\", headers=auth_headers)\n",
    "\n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "        \n",
    "        # Model base information\n",
    "        base_info_df = json_normalize(response_json)\n",
    "        base_info_df.drop(\n",
    "            columns=[\n",
    "                'gddUnits', 'stages', '_links.self.href', \n",
    "                '_links.curies', '_links.awhere:model.href'\n",
    "            ], inplace=True)\n",
    "        base_info_df['model_id'] = model_id\n",
    "        base_info_df.set_index('model_id', inplace=True)\n",
    "        base_info_df.rename(columns={\n",
    "            'biofix': 'biofix_days',\n",
    "            'gddMethod': 'gdd_method',\n",
    "            'gddBaseTemp': 'gdd_base_temp_cels',\n",
    "            'gddMaxBoundary': 'gdd_max_boundary_cels',\n",
    "            'gddMinBoundary': 'gdd_min_boundary_cels'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Model stage information\n",
    "        stage_info_df = json_normalize(response_json.get('stages'))\n",
    "        stage_info_df.drop(columns=['gddUnits'], inplace=True)\n",
    "        stage_info_df['model_id'] = model_id\n",
    "        stage_info_df.rename(columns={\n",
    "            'id': 'stage_id',\n",
    "            'stage': 'stage_name',\n",
    "            'description': 'stage_description',\n",
    "            'gddThreshold': 'gdd_threshold_cels',\n",
    "        }, inplace=True)\n",
    "        stage_info_df.set_index(['model_id', 'stage_id'], inplace=True)\n",
    "        \n",
    "        # Return base info and stage info dataframes\n",
    "        return base_info_df, stage_info_df\n",
    "    \n",
    "#     def get_all_details(self):\n",
    "#         \"\"\"Get dataframes with details on all\n",
    "#         available models.\n",
    "#         \"\"\"\n",
    "#         # Lists to store dataframes\n",
    "#         base_list = []\n",
    "#         stage_list = []\n",
    "\n",
    "#         for model in list(self.get_full().index):\n",
    "#             base, stage = self.get_details(model_id=model)\n",
    "#             base_list.append(base)\n",
    "#             stage_list.append(stage)\n",
    "\n",
    "#         base_df_all = pd.concat(base_list, axis=0)\n",
    "#         stage_df_all = pd.concat(stage_list, axis=0)\n",
    "        \n",
    "#         return base_df_all, stage_df_all\n",
    "    \n",
    "    @classmethod\n",
    "    def get_all_details(cls, api_object):\n",
    "        \"\"\"Get dataframes with details on all\n",
    "        available models.\n",
    "        \"\"\"\n",
    "        # Lists to store dataframes\n",
    "        base_list = []\n",
    "        stage_list = []\n",
    "\n",
    "        for model in list(api_object.get_full().index):\n",
    "            base, stage = api_object.get_details(model_id=model)\n",
    "            base_list.append(base)\n",
    "            stage_list.append(stage)\n",
    "\n",
    "        base_df_all = pd.concat(base_list, axis=0)\n",
    "        stage_df_all = pd.concat(stage_list, axis=0)\n",
    "        \n",
    "        return base_df_all, stage_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = AgronomicsModels(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, t = AgronomicsModels.get_all_details(model_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, s = model_object.get_all_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = model_object.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base, stage = model_object.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_normalize(model_object.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(model_object.get_details().get('stages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stage_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.get(model_id='BarleyGenericNDAWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_object.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(model_object.get(model_id='BarleyGenericNDAWN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(model_object.get().get('models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsPlantings(Agronomics):\n",
    "\n",
    "    def __init__(self, api_key, api_secret, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsPlantings, self).__init__(api_key, api_secret,\n",
    "                                                  base_64_encoded_secret_key, auth_token)\n",
    "\n",
    "        self.api_url = f'{self.api_url}/plantings'\n",
    "\n",
    "    def get(self, planting_id=None, limit=10, offset=0):\n",
    "        \"\"\"Returns aWhere plantings associated with your account.\n",
    "\n",
    "        planting_id can either be an actual id or 'current' for the most\n",
    "        current planting. 'None' will result in all planting.      \n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "            # \"Content-Type\": 'application/json'\n",
    "        }\n",
    "\n",
    "        # Get API response\n",
    "        response = requests.get(f\"{self.api_url}/{planting_id}\", headers=auth_headers) if planting_id else requests.get(\n",
    "            f\"{self.api_url}?limit={limit}&offset={offset}\", headers=auth_headers)\n",
    "\n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Convert to dataframe\n",
    "        response_df = json_normalize(response_json.get('plantings')) if response_json.get(\n",
    "            'plantings') else json_normalize(response_json)\n",
    "\n",
    "        drop_cols = [\n",
    "            '_links.self.href', '_links.curies',\n",
    "            '_links.awhere:crop.href', '_links.awhere:field.href'\n",
    "        ]\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        response_df.drop(\n",
    "            columns=drop_cols, inplace=True)\n",
    "\n",
    "        # Define new column names\n",
    "        planting_rename = {\n",
    "            'id': 'planting_id',\n",
    "            'crop': 'crop_id',\n",
    "            'field': 'field_id',\n",
    "            'plantingDate': 'planting_date',\n",
    "            'harvestDate': 'harvest_date_actual',\n",
    "            # What is 'recommendation' field? What output goes here, and where does it come from?\n",
    "            # {response_json.get(\"yield\").get(\"units\").lower()}',\n",
    "            'yield.amount': 'yield_amount_actual',\n",
    "            'yield.units': 'yield_amount_actual_units',\n",
    "            # {response_json.get(\"projections\").get(\"yield\").get(\"units\").lower()}',\n",
    "            'projections.yield.amount': 'yield_amount_projected',\n",
    "            'projections.yield.units': 'yield_amount_projected_units',\n",
    "            'projections.harvestDate': 'harvest_date_projected'\n",
    "        }\n",
    "\n",
    "        # Rename\n",
    "        response_df.rename(columns=planting_rename, inplace=True)\n",
    "\n",
    "        # Set index\n",
    "        response_df.set_index('planting_id', inplace=True)\n",
    "\n",
    "        return response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_plant = AgronomicsPlantings(api_key, api_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_plant.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_plant.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_plant.get(planting_id=464537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agro_plant.get(planting_id='current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgronomicsFieldModels(AgronomicsField):\n",
    "\n",
    "    # Define field_id intitializing class\n",
    "    def __init__(self, api_key, api_secret, field_id, model_id, base_64_encoded_secret_key=None,\n",
    "                 auth_token=None, api_url=None):\n",
    "\n",
    "        super(AgronomicsFieldModels, self).__init__(\n",
    "            api_key, api_secret, base_64_encoded_secret_key, auth_token, api_url)\n",
    "\n",
    "        self.field_id = field_id\n",
    "        self.model_id = model_id\n",
    "        self.api_url = f\"{self.api_url}/{self.field_id}/models/{model_id}/results\"\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"Returns aWhere model associated with a field.      \n",
    "        \"\"\"\n",
    "        # Setup the HTTP request headers\n",
    "        auth_headers = {\n",
    "            \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "            # \"Content-Type\": 'application/json'\n",
    "        }\n",
    "\n",
    "        # Get API response\n",
    "        response = requests.get(\n",
    "            f\"{self.api_url}\", headers=auth_headers)\n",
    "\n",
    "        # Convert API response to JSON format\n",
    "        response_json = response.json()\n",
    "\n",
    "        # Get stage info\n",
    "        previous_stage_df = json_normalize(response_json.get('previousStages'))\n",
    "        current_stage_df = json_normalize(response_json.get('currentStage'))\n",
    "        next_stage_df = json_normalize(response_json.get('nextStage'))\n",
    "\n",
    "        # Add columns\n",
    "        previous_stage_df['stage_status'] = 'Previous'\n",
    "        current_stage_df['stage_status'] = 'Current'\n",
    "        next_stage_df['stage_status'] = 'Next'\n",
    "\n",
    "        # Merge into one dataframe\n",
    "        stages_df = pd.concat([\n",
    "            previous_stage_df, current_stage_df, next_stage_df],\n",
    "            sort=False, axis=0)\n",
    "\n",
    "        # Change column names\n",
    "        stages_df.rename(columns={\n",
    "            'date': 'stage_start_date',\n",
    "            'id': 'stage_id',\n",
    "            'stage': 'stage_name',\n",
    "            'description': 'stage_description',\n",
    "            'gddThreshold': 'gdd_threshold_cels',\n",
    "            'accumulatedGdds': 'gdd_accumulation_current_cels',\n",
    "            'gddRemaining': 'gdd_remaining_next_cels'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Add base data\n",
    "        stages_df['biofix_date'] = response_json.get('biofixDate')\n",
    "        stages_df['planting_date'] = response_json.get('plantingDate')\n",
    "        stages_df['model_id'] = response_json.get('modelId')\n",
    "        stages_df['field_id'] = response_json.get('location').get('fieldId')\n",
    "        stages_df['longitude'] = response_json.get('location').get('longitude')\n",
    "        stages_df['latitude'] = response_json.get('location').get('latitude')\n",
    "\n",
    "        # Set index\n",
    "        stages_df.set_index(['field_id', 'stage_status'], inplace=True)\n",
    "\n",
    "        # Prep for geodataframe conversion\n",
    "        df_copy = stages_df.copy()\n",
    "\n",
    "        # Define CRS (EPSG 4326)\n",
    "        crs = {'init': 'epsg:4326'}\n",
    "\n",
    "        # Convert to geodataframe\n",
    "        stages_gdf = gpd.GeoDataFrame(\n",
    "            df_copy, crs=crs, geometry=gpd.points_from_xy(\n",
    "                stages_df.longitude,\n",
    "                stages_df.latitude)\n",
    "        )\n",
    "\n",
    "        # Drop lat/lon\n",
    "        stages_gdf.drop(columns=['longitude', 'latitude'], inplace=True)\n",
    "\n",
    "        # Reorder columns\n",
    "        stages_gdf = stages_gdf.reindex(columns=[\n",
    "            'model_id', 'biofix_date', 'planting_date',\n",
    "            'stage_start_date', 'stage_id', 'stage_name',\n",
    "            'stage_description', 'gdd_threshold_cels',\n",
    "            'gdd_accumulation_current_cels', 'gdd_remaining_next_cels',\n",
    "            'geometry'\n",
    "        ])\n",
    "\n",
    "        return stages_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object = AgronomicsFieldModels(\n",
    "    api_key, api_secret, field_id='CO-RMNP-Bear-Lake', model_id='SorghumLongSeasonTexasAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.get(model_id='SorghumLongSeasonTexasAM') # WheatHardRedMSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_object.api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_object.get(model_id='WheatHardRedMSU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object.get_base(model_id='SorghumLongSeasonTexasAM') # WheatHardRedMSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def get_base(self, model_id):\n",
    "#         \"\"\"Returns aWhere plantings associated with a specified field.\n",
    "\n",
    "#         planting_id can either be an actual id or 'current' for the most\n",
    "#         current planting. 'None' will result in all plantings\n",
    "\n",
    "#         GET /v2/agronomics/fields/{fieldId}/plantings\n",
    "#         GET /v2/agronomics/fields/{fieldId}/plantings/{plantingId}\n",
    "#         GET /v2/agronomics/fields/{fieldId}/plantings/current        \n",
    "#         \"\"\"\n",
    "\n",
    "#         # Setup the HTTP request headers\n",
    "#         auth_headers = {\n",
    "#             \"Authorization\": f\"Bearer {self.auth_token}\"\n",
    "#             # \"Content-Type\": 'application/json'\n",
    "#         }\n",
    "\n",
    "#         # Get API response\n",
    "#         response = requests.get(\n",
    "#             f\"{self.api_url}/{model_id}/results\", headers=auth_headers)\n",
    "\n",
    "#         # BASE INFORMATION\n",
    "#         # Convert API response to JSON format\n",
    "#         response_json = response.json()\n",
    "\n",
    "#         # Convert to dataframe\n",
    "#         response_df = json_normalize(response_json)\n",
    "\n",
    "#         drop_cols = [\n",
    "#             'previousStages', 'gddUnits', 'currentStage.accumulatedGdds',\n",
    "#             'currentStage.date', 'currentStage.id', 'currentStage.stage',\n",
    "#             'currentStage.description', 'currentStage.gddThreshold', 'nextStage.description',\n",
    "#             'nextStage.gddThreshold', 'nextStage.gddRemaining', 'nextStage.id',\n",
    "#             'nextStage.stage', '_links.self.href', '_links.curies', '_links.awhere:model.href',\n",
    "#             '_links.awhere:modelDetails.href', '_links.awhere:field.href', '_links.awhere:planting.href'\n",
    "#         ]\n",
    "\n",
    "#         # Drop unnecessary columns\n",
    "#         response_df.drop(\n",
    "#             columns=drop_cols, inplace=True)\n",
    "\n",
    "#         # Define new column names\n",
    "#         model_rename = {\n",
    "#             'biofixDate': 'biofix_date',\n",
    "#             'modelId': 'model_id',\n",
    "#             'plantingDate': 'planting_date',\n",
    "#             'location.latitude': 'latitude',\n",
    "#             'location.longitude': 'longitude',\n",
    "#             'location.fieldId': 'field_id'\n",
    "#         }\n",
    "\n",
    "#         # Rename\n",
    "#         response_df.rename(columns=model_rename, inplace=True)\n",
    "\n",
    "#         # Set index\n",
    "#         # ['field_id', 'model_id']\n",
    "#         response_df.set_index('field_id', inplace=True)\n",
    "\n",
    "#         # Prep for geodataframe conversion\n",
    "#         df_copy = response_df.copy()\n",
    "\n",
    "#         # Define CRS (EPSG 4326)\n",
    "#         crs = {'init': 'epsg:4326'}\n",
    "\n",
    "#         # Convert to geodataframe\n",
    "#         response_gdf = gpd.GeoDataFrame(\n",
    "#             df_copy, crs=crs, geometry=gpd.points_from_xy(\n",
    "#                 response_df.longitude,\n",
    "#                 response_df.latitude)\n",
    "#         )\n",
    "\n",
    "#         # Drop lat/lon\n",
    "#         response_gdf.drop(columns=['longitude', 'latitude'], inplace=True)\n",
    "\n",
    "#         return response_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM').get('previousStages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM').get('currentStage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM').get('nextStage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM').get('previousStages')), \n",
    "    json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM').get('currentStage')),\n",
    "    json_normalize(model_object.get(model_id='SorghumLongSeasonTexasAM').get('nextStage'))\n",
    "], sort=False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
